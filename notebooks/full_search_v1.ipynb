{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import bz2\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "from unicode_codes import EMOJI_UNICODE\n",
    "from twitter_search_funcs import *\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/your/data/path/archive-twitter-2016-08/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Character to match\n",
    "match = EMOJI_UNICODE[':pistol:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counters\n",
    "counter_total_tweets = 0\n",
    "counter_total_match = 0\n",
    "counter_total_before = 0\n",
    "counter_total_after = 0\n",
    "counterdict_before = {}\n",
    "counterdict_after = {}\n",
    "counterdict_lang = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main search loop\n",
    "start_t = timer()\n",
    "for day in range(31):\n",
    "    day_str = \"{:02d}\".format(day + 1)\n",
    "    for hour in range(24):\n",
    "        hour_str = \"{:02d}\".format(hour)\n",
    "        file_path = os.path.join(data_path, day_str, hour_str)\n",
    "        files = os.listdir(file_path)\n",
    "        for i, f in enumerate(files):\n",
    "            progress(i + hour * len(files), \n",
    "                     len(files) * 24, \n",
    "                     suffix=\"Searching Day {}, Hour {}\".format(day_str, hour_str))\n",
    "            fbz = bz2.BZ2File(os.path.join(file_path, f), 'rb')\n",
    "            try:\n",
    "                fdec = fbz.read()\n",
    "            except IOError:\n",
    "                continue\n",
    "            finally:\n",
    "                fbz.close()\n",
    "            fdecutf = fdec.decode('utf-8')\n",
    "\n",
    "            for t in fdecutf.split('\\n'):\n",
    "                try:\n",
    "                    tweet = json.loads(t)\n",
    "                except (ValueError):\n",
    "                    continue\n",
    "                if 'delete' in tweet.keys():\n",
    "                    continue\n",
    "                counter_total_tweets += 1\n",
    "                if match in tweet['text']:\n",
    "                    counter_total_match += 1\n",
    "                    result = find_context(tweet['text'], match)\n",
    "\n",
    "                    if result[0] in EMOJI_UNICODE.values():\n",
    "                        counter_total_before += 1\n",
    "\n",
    "                        if result[0] in counterdict_before.keys():\n",
    "                            counterdict_before[result[0]] += 1\n",
    "                        else:\n",
    "                            counterdict_before[result[0]] = 1\n",
    "\n",
    "                    if result[2] in EMOJI_UNICODE.values():\n",
    "                        counter_total_after += 1\n",
    "                        \n",
    "                        if result[2] in counterdict_after.keys():\n",
    "                            counterdict_after[result[2]] += 1\n",
    "                        else:\n",
    "                            counterdict_after[result[2]] = 1\n",
    "                    \n",
    "                    try:\n",
    "                        if tweet['lang'] in counterdict_lang.keys():\n",
    "                            counterdict_lang[tweet['lang']] += 1\n",
    "                        else:\n",
    "                            counterdict_lang[tweet['lang']] = 1\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "end_t = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print outputs\n",
    "print(\"Elapsed Time    : {:.2f} min\".format((end_t - start_t) / 60))\n",
    "print(\"Total Tweets    : {:d}\".format(counter_total_tweets))\n",
    "print(\"Total Matches   : {:d}\".format(counter_total_match))\n",
    "print(\"Total w/ Before : {:d}\".format(counter_total_before))\n",
    "print(\"Total w/ After  : {:d}\".format(counter_total_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert output to dataframe\n",
    "df_before = pd.DataFrame(list(counterdict_before.items()), columns=['Emoji', 'CountBefore'])\n",
    "df_after = pd.DataFrame(list(counterdict_after.items()), columns=['Emoji', 'CountAfter'])\n",
    "df_lang = pd.DataFrame(list(counterdict_lang.items()), columns=['Lang', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge before and after dataframes\n",
    "df_all = pd.merge(df_before, df_after, on='Emoji', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.sort_values('CountBefore', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.sort_values('CountAfter', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lang.sort_values('Count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.sort_values('CountBefore', ascending=False).head(20).plot.bar(y='CountBefore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.sort_values('CountAfter', ascending=False).head(20).plot.bar(y='CountAfter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export results as CSV files\n",
    "df_all.to_csv(\"./alldata.csv\")\n",
    "df_lang.to_csv(\"./langdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
